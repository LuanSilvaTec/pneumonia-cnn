{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjRXT9l7Stak"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = './gdrive/My Drive/Faculdade/CBIC_LUAN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7r9o-mSzGy",
        "outputId": "5318284c-0720-4783-90a4-6861a15d4604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "import h5py\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras_applications.resnext import ResNeXt50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import os\n",
        "import glob\n",
        "\n",
        "ext_img = '.jpg'\n",
        "num_px = 75\n",
        "num_py = 75\n",
        "total_imgs = 5856     # total of images considering all classes\n",
        "base_name = '/content/gdrive/My Drive/Faculdade/CBIC_LUAN' # main folder\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 16  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Load data\n",
        "hf = h5py.File(os.path.join(base_name, 'base_antiga.h5'), 'r')\n",
        "x_train = np.array(hf.get('x_train'))\n",
        "x_test = np.array(hf.get('x_test'))\n",
        "y_train = np.array(hf.get('y_train'))\n",
        "y_test = np.array(hf.get('y_test'))\n",
        "\n",
        "labels_dic = {}\n",
        "for l in hf.keys():\n",
        "    if 'x_train' not in l and 'x_test' not in l and 'y_train' not in l and 'y_test' not in l:\n",
        "        print(hf[l].value)\n",
        "        print(l)\n",
        "        labels_dic[hf[l].value] = l\n",
        "\n",
        "hf.close()\n",
        "\n",
        "print(\"Train shape\" + str(x_train.shape))\n",
        "print(\"Test shape\" + str(x_test.shape))\n",
        "#print(\"Label test: \" + str(labels_dic[0]))\n",
        "\n",
        "#n = 8\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "#version = 1\n",
        "\n",
        "\n",
        "# Model name, depth and version\n",
        "#model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "   \n",
        "############################################################################################\n",
        "#NEW PART\n",
        "#base_model = VGG16(include_top=False, weights=None, input_tensor=None, input_shape=input_shape)\n",
        "#base_model = InceptionV3(include_top=False, weights=None, input_tensor=None, input_shape=input_shape,\n",
        "#base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=input_shape)\n",
        "base_model= InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=input_shape)\n",
        "#base_model= ResNeXt50(include_top=False, weights=None, input_shape=input_shape,\n",
        "                            backend=keras.backend,\n",
        "                            layers=keras.layers,\n",
        "                            models=keras.models,\n",
        "                            utils=keras.utils)\n",
        "\n",
        "model_type = 'InceptionResNetV2'\n",
        "directory_results = '/content/gdrive/Faculdade/CBIC_LUAN/resultados/'\n",
        "model_name= 'InceptionResNetV2'\n",
        "\n",
        "model = base_model.output\n",
        "model = GlobalAveragePooling2D()(model)\n",
        "model = Dense(128, activation='relu')(model)\n",
        "model = Dropout(0.2)(model)\n",
        "\n",
        "predictions = Dense(num_classes, activation='sigmoid',kernel_initializer='he_normal')(model)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "#########################################################################\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(base_name, 'saved_models')\n",
        "model_name = 'XDB32_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    h = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    h = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        validation_steps=x_test.shape[0] // batch_size,\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "######################################################################################################\n",
        "\n",
        "\n",
        "##Cria uma nova pasta para a respectiva execução\n",
        "\n",
        "if os.path.exists(directory_results+model_name) == False:\n",
        "  os.mkdir(directory_results+model_name)\n",
        "     \n",
        "directory_results = directory_results+model_name\n",
        "tamanho_directory = len(directory_results)+1\n",
        "\n",
        "lista = [os.path.join(directory_results, o) for o in os.listdir(directory_results) \n",
        "                    if os.path.isdir(os.path.join(directory_results,o))]\n",
        "count = 0\n",
        "for pasta in lista:\n",
        "  count=int(pasta[tamanho_directory:])\n",
        "\n",
        "count+=1\n",
        "os.mkdir(directory_results+'/'+str(count))\n",
        "directory_results = directory_results+'/'+str(count)+'/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.save_weights(os.path.join(directory_results,model_name+'.h5'))#save weights\n",
        "\n",
        "print(h)\n",
        "# History of acc(train) and val_acc(validation)\n",
        "hist_acc_train = h.history['acc']\n",
        "hist_loss_train = h.history['loss']\n",
        "hist_acc_test = h.history['val_acc']\n",
        "hist_loss_test = h.history['val_loss']\n",
        "\n",
        "print('History of train\\n', hist_acc_train)\n",
        "print('History of test\\n', hist_acc_test)\n",
        "\n",
        "np.save(directory_results+model_name+'_acc_train.npy',hist_acc_train)\n",
        "np.save(directory_results+model_name+'_loss_train.npy',hist_loss_train)\n",
        "np.save(directory_results+model_name+'_acc_test.npy',hist_acc_test)\n",
        "np.save(directory_results+model_name+'_loss_test.npy',hist_loss_test)\n",
        "\n",
        "\n",
        "# plot history\n",
        "plt.figure(1)\n",
        "plt.plot(hist_loss_train)\n",
        "plt.plot(hist_loss_test)\n",
        "plt.legend(['Train loss','Test loss'], loc='upper right')\n",
        "plt.title('Learning curves')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(hist_acc_train)\n",
        "plt.plot(hist_acc_test)\n",
        "plt.legend(['Train acc','Test acc'], loc='upper right')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Report\n",
        "pred_test = np.argmax(model.predict(x_test, batch_size=1, verbose=0), axis=1)\n",
        "true_test = np.argmax(y_test, axis=1)\n",
        "cf = confusion_matrix(true_test, pred_test)\n",
        "print(cf)\n",
        "\n",
        "np.save(directory_results+model_name+'_pred_test.npy',pred_test)\n",
        "np.save(directory_results+model_name+'_true_test.npy',true_test)\n",
        "np.save(directory_results+model_name+'_cf.npy',cf)\n",
        "\n",
        "\n",
        "if(not os.path.exists(directory_results+model_name+'.txt')):\n",
        "  file = open(directory_results+model_name+'.txt', 'w')\n",
        "  file.close()\n",
        "\n",
        "file = open(directory_results+model_name+'.txt', 'r')\n",
        "\n",
        "lines = file.readlines()\n",
        "\n",
        "results_class = []\n",
        "for cl in range(num_classes):\n",
        "  print(\"\\n%s: %.2f%%\" % (labels_dic[cl], cf[cl,cl]/sum(true_test==cl)*100))\n",
        "  lines.append(\"\\n%s: %.2f%%\" % (labels_dic[cl], cf[cl,cl]/sum(true_test==cl)*100))\n",
        "  results_class.append(cf[cl,cl]/sum(true_test==cl)*100)\n",
        "\n",
        "np.save(directory_results+model_name+'_results_class.npy',results_class)\n",
        "labels = []\n",
        "for i in labels_dic:\n",
        "  labels.append(labels_dic[i])\n",
        "np.save(directory_results+model_name+'_labels.npy',labels)\n",
        "\n",
        "print(labels_dic.values())\n",
        "print(classification_report(true_test, pred_test, target_names=labels_dic.values()))\n",
        "lines.append(\"\\n\"+str(classification_report(true_test, pred_test, target_names=labels_dic.values())))\n",
        "\n",
        "# save file execution\n",
        "file = open(directory_results+model_name+'.txt', 'w')\n",
        "file.writelines(lines)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NORMAL\n",
            "1\n",
            "PNEUMONIA\n",
            "Train shape(4684, 75, 75, 3)\n",
            "Test shape(1172, 75, 75, 3)\n",
            "4684 train samples\n",
            "1172 test samples\n",
            "x_train shape: (4684, 75, 75, 3)\n",
            "y_train shape: (4684, 1)\n",
            "x_test shape: (1172, 75, 75, 3)\n",
            "y_test shape: (1172, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "Learning rate:  0.001\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 37, 37, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 37, 37, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 37, 37, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 35, 35, 32)   9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 35, 35, 32)   96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 35, 35, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 64)   18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 64)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 17, 17, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 17, 17, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 15, 15, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 15, 15, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 15, 15, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 64)     192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 64)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 96)     55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 48)     144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 48)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 64)     76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 96)     82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 64)     192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 96)     288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 32)     96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 96)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 32)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 64)     192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 7, 7, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 7, 96)     55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 48)     144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 96)     288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 48)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 7, 7, 96)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 64)     76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 7, 7, 96)     82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 7, 7, 64)     192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 64)     192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 7, 7, 96)     288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 64)     192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 7, 7, 96)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 7, 7, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 64)     192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 96)     55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 48)     144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 96)     288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 7, 7, 48)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 96)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 64)     76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 96)     82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 64)     192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 64)     192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 96)     288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 64)     192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 7, 7, 64)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 7, 7, 64)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 96)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 64)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 64)     192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 64)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 3, 3, 96)     82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 3, 3, 384)    1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 3, 3, 96)     288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 384)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 96)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 3, 3, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 3, 3, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 3, 3, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 3, 3, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 3, 3, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 3, 3, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 3, 3, 128)    114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 3, 3, 128)    114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 3, 3, 128)    384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 3, 3, 128)    384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 128)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 128)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 3, 3, 192)    172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 3, 3, 192)    172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 3, 3, 192)    576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 3, 3, 192)    576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 3, 3, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 3, 3, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 192)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 192)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 3, 3, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 3, 3, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 3, 3, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 3, 3, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 3, 3, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 3, 3, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 3, 3, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 3, 3, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 3, 3, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 3, 3, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 3, 3, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 3, 3, 160)    179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 3, 3, 160)    179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 3, 3, 160)    480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 3, 3, 160)    480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 3, 3, 160)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 3, 3, 160)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 3, 3, 192)    215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 3, 3, 192)    215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 3, 3, 192)    576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 3, 3, 192)    576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 3, 3, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 3, 3, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 3, 3, 192)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 3, 3, 192)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 3, 3, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 3, 3, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 3, 3, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 3, 3, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 3, 3, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 3, 3, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 3, 3, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 3, 3, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 3, 3, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 3, 3, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 3, 3, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 3, 3, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 3, 3, 160)    179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 3, 3, 160)    179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 3, 3, 160)    480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 3, 3, 160)    480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 3, 3, 160)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 3, 3, 160)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 3, 3, 192)    215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 3, 3, 192)    215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 3, 3, 192)    576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 3, 3, 192)    576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 3, 3, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 3, 3, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 3, 3, 192)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 3, 3, 192)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 3, 3, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 3, 3, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 3, 3, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 3, 3, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 3, 3, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 3, 3, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 3, 3, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 3, 3, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 3, 3, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 3, 3, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 3, 3, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 3, 3, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 3, 3, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 3, 3, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 3, 3, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 3, 3, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 3, 3, 192)    258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 3, 3, 192)    258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 3, 3, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 3, 3, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 3, 3, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 3, 3, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 3, 3, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 3, 3, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 3, 3, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 3, 3, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 3, 3, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 192)    576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 192)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 1, 1, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 1, 1, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 1, 1, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 1, 1, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 1, 1, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 1, 1, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 1, 1, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 1, 1, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 1, 1, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 1, 1, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 1, 1, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 1, 1, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 1, 1, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 1, 1, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 1, 1, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 1, 1, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 1, 1, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 1, 1, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 1, 1, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 1, 1, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 1, 1, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 1, 1, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 1, 1, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 1, 1, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 1, 1, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 1, 1, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 1, 1, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          262272      global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,065,314\n",
            "Trainable params: 22,030,882\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 58s 200ms/step - loss: 0.3767 - acc: 0.8445 - val_loss: 0.2961 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.87543, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.001.h5\n",
            "Epoch 2/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 34s 117ms/step - loss: 0.3031 - acc: 0.8830 - val_loss: 0.3442 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.87543 to 0.92619, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.002.h5\n",
            "Epoch 3/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 33s 113ms/step - loss: 0.2563 - acc: 0.9033 - val_loss: 0.1921 - val_acc: 0.9360\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92619 to 0.93601, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.003.h5\n",
            "Epoch 4/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 33s 114ms/step - loss: 0.2257 - acc: 0.9186 - val_loss: 0.1464 - val_acc: 0.9411\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.93601 to 0.94113, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.004.h5\n",
            "Epoch 5/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 108ms/step - loss: 0.2464 - acc: 0.9084 - val_loss: 0.4787 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.94113\n",
            "Epoch 6/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 106ms/step - loss: 0.2904 - acc: 0.8905 - val_loss: 0.4224 - val_acc: 0.9305\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.94113\n",
            "Epoch 7/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 32s 109ms/step - loss: 0.2271 - acc: 0.9187 - val_loss: 0.1829 - val_acc: 0.9424\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.94113 to 0.94241, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.007.h5\n",
            "Epoch 8/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 106ms/step - loss: 0.2359 - acc: 0.9133 - val_loss: 0.1760 - val_acc: 0.9458\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.94241 to 0.94582, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.008.h5\n",
            "Epoch 9/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 106ms/step - loss: 0.2207 - acc: 0.9237 - val_loss: 0.1555 - val_acc: 0.9386\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.94582\n",
            "Epoch 10/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 30s 104ms/step - loss: 0.1861 - acc: 0.9403 - val_loss: 0.2696 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.94582\n",
            "Epoch 11/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 107ms/step - loss: 0.1943 - acc: 0.9360 - val_loss: 0.2814 - val_acc: 0.8814\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.94582\n",
            "Epoch 12/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 31s 106ms/step - loss: 0.1714 - acc: 0.9422 - val_loss: 0.1471 - val_acc: 0.9531\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.94582 to 0.95307, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.012.h5\n",
            "Epoch 13/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 32s 108ms/step - loss: 0.1750 - acc: 0.9397 - val_loss: 0.1148 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.95307 to 0.95990, saving model to /content/gdrive/My Drive/Faculdade/CBIC_LUAN/saved_models/XDB32_InceptionV3_model.013.h5\n",
            "Epoch 14/200\n",
            "Learning rate:  0.001\n",
            "292/292 [==============================] - 32s 109ms/step - loss: 0.1654 - acc: 0.9456 - val_loss: 0.1521 - val_acc: 0.9428\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.95990\n",
            "Epoch 15/200\n",
            "Learning rate:  0.001\n",
            "261/292 [=========================>....] - ETA: 3s - loss: 0.1646 - acc: 0.9432"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}